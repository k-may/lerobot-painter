{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from lerobot.robots.so101_follower import SO101FollowerConfig\n",
    "from lerobot.teleoperators.so101_leader import SO101LeaderConfig\n",
    "\n",
    "leader_port ='/dev/tty.usbmodem5A460826291'\n",
    "leader_id = \"my_leader\"\n",
    "follower_port = '/dev/tty.usbmodem5A460840631'\n",
    "follower_id = \"my_follower\"\n",
    "\n",
    "\n",
    "robot_config = SO101FollowerConfig(\n",
    "    port=follower_port,\n",
    "    id=follower_id,\n",
    ")\n",
    "\n",
    "teleop_config = SO101LeaderConfig(\n",
    "    port=leader_port,\n",
    "    id=leader_id\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Calibrate the robots\n",
    "```\n",
    "lerobot-calibrate --robot.type=so101_follower --robot.port=/dev/tty.usbmodem5A460826291 --robot.id=my_follower\n",
    "lerobot-calibrate --teleop.type=so101_leader --teleop.port=/dev/tty.usbmodem5A460840631 --teleop.id=my_leader\n",
    "\n",
    "lerobot-teleoperate --robot.type=so101_follower --robot.port=/dev/tty.usbmodem5A460840631 --robot.id=my_follower --teleop.type=so101_leader --teleop.port=/dev/tty.usbmodem5A460826291 --teleop.id=my_leader\n",
    "```"
   ],
   "id": "984056c7939f1fe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lerobot.teleoperators.so101_leader import SO101Leader\n",
    "\n",
    "leader = SO101Leader(teleop_config)\n",
    "leader.connect(calibrate=False)\n",
    "leader.calibrate()\n",
    "leader.disconnect()"
   ],
   "id": "4613f6fd792e0580",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lerobot.robots.so101_follower import SO101Follower\n",
    "\n",
    "follower = SO101Follower(robot_config)\n",
    "follower.connect()\n",
    "follower.calibrate()\n",
    "follower.disconnect()\n"
   ],
   "id": "aa1c26f67ba10b98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To solve:\n",
    "1. calibrating a geometrical drawing plane in the robots space\n",
    "2. define a path of movement whereby the robots pencil moves along the path of a shape constrained to this plane"
   ],
   "id": "d83fdf0f16c6f60c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1) Calibrate the drawing plane\n",
    "\n",
    "Goal: compute a rigid transform that maps 2D coordinates on your drawing plane (u, v) → 3D robot/world coordinates Pw. Also compute the plane normal so you can orient the pencil.\n",
    "\n",
    "Inputs you’ll produce from the robot:\n",
    "\n",
    "- a few measured 3D points (Pi) in the robot base/world frame obtained by touching the tip to known points on the drawing surface (or by probing).\n",
    "\n",
    "**Recommended methods**\n",
    "- Minimum (fast): touch three non-collinear points on the surface → compute plane exactly.\n",
    "- Better (robust): probe many points (N ≥ 6) and do a least-squares plane fit (SVD).\n",
    "\n",
    "**Math & algorithm (robust fit)**\n",
    "\n",
    "1. Collect points Pi  ∈ R3 (robot frame).\n",
    "2. Compute centroid  $\\bar{p} = \\frac{1}{N} \\sum_i p_i$.\n",
    "3. Center points: $ q_i = p_i - \\bar{p}$.\n",
    "4. SVD on data matrix $Q = [q_1, ..., q_N]^T$. The plane normal $ 𝑛 $ is the singular vector corresponding to smallest singular value.\n",
    "5. Choose a local 2D basis on the plane: pick $ 𝑢 = normalized( p_2 - p_1 )$ (or use any vector not parallel to n), then $ v = n x n $\n",
    "6. Origin of plane = $ O = \\bar{p}$ (or one of the measured points).\n",
    "7. The plane frame axes are $(𝑢,𝑣,𝑛)$ and origin $O$.\n",
    "\n",
    "\n",
    "You now have a 4×4 transform\n",
    "```\n",
    "[ u.x  v.x  n.x  O.x ]\n",
    "[ u.y  v.y  n.y  O.y ]\n",
    "[ u.z  v.z  n.z  O.z ]\n",
    "[  0    0    0    1  ]\n",
    "```\n",
    "\n",
    "\n"
   ],
   "id": "675e3b697b56c72c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Projecting between frames:**",
   "id": "275aa1817e260535"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def fit_plane_svd(points):\n",
    "    # points: (N,3) numpy array in robot/world frame\n",
    "    centroid = points.mean(axis=0)\n",
    "    Q = points - centroid\n",
    "    # SVD\n",
    "    _, _, vh = np.linalg.svd(Q, full_matrices=False)\n",
    "    normal = vh[-1, :]           # smallest singular vector\n",
    "    normal = normal / np.linalg.norm(normal)\n",
    "    # choose u axis: vector from first to second point projected onto plane\n",
    "    tmp = points[1] - points[0]\n",
    "    u = tmp - np.dot(tmp, normal) * normal\n",
    "    u = u / np.linalg.norm(u)\n",
    "    v = np.cross(normal, u)\n",
    "    T = np.eye(4)\n",
    "    T[0:3,0] = u\n",
    "    T[0:3,1] = v\n",
    "    T[0:3,2] = normal\n",
    "    T[0:3,3] = centroid\n",
    "    return T, u, v, normal, centroid"
   ],
   "id": "15d12e5948d4f327",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How to probe points with the robot:\n",
    "- Move the robot to a position above the drawing surface.\n",
    "- Lower the robot until the pencil just touches the surface (you can use force sensing or a small offset).\n",
    "- Record the robot's end-effector position as a 3D point.\n",
    "- Repeat for multiple points on the drawing surface."
   ],
   "id": "436b338756b05bdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 2) Define and execute drawing paths constrained to that plane\n",
    "\n",
    "Workflow : create 2D shape => sample/resample into points along path -> map points tp plane3D -> generate EE poses with correct orientation and Z offsets -> IK to joint targets -> trajectory execution with smoothing\n",
    "\n",
    "#### Step A - Represent the 2D path\n",
    "\n",
    "options:\n",
    "- Vector format (SVG / paths) --preferred for shapes and text.\n",
    "- Paramettric definitions (circle, bezier, lines).\n",
    "- Raster -> contours (for image tracing).\n",
    "\n",
    "You can parse and SVG path to a sequence of 2D curves and the sample them at resolution $ d_s $ (mm per step)\n",
    "\n",
    "#### Step B -- Resample / smooth\n",
    "- Resample so consequtive points are within a chosen distance (e.g. 0.5-2 mm).\n",
    "- Apply a small smoothing filter if desired.\n",
    "\n",
    "#### Step C -- Convert 2D sample points to 3D world\n",
    "For each sampled 2D pont (s, t):\n",
    "* Computer world position `p_w = O + s*u + t*v`\n",
    "* Typical drawing poses:\n",
    "    * `hover_pose` at `z=+h` mm above the plane\n",
    "    * `contact_pose` at `z=-d` relative to the plane origin where pencil contacts (small negative offset along normal) -- or simply `z` at plane minus a small penetration if required for pressure\n",
    "\n",
    "Make the EE orientation such that the toll frames's z-axis aligns with `-normal` (pencil pointing toward plane). You can compose a rotation matrix `R` where the third column = `-normal`.\n",
    "\n",
    "#### Step D -- Solve IK & trajectory interpolation\n",
    "* For each 3D pose (position + orientation), compute joint angles with your robots's IK.\n",
    "    * If IK fails at any pose, try small perturbations, or plan in joint space.\n",
    "* Option 1 -- Task-space interpolation: for eahc adjacent sample, compute IK for each sampled pose (keeps straight line in task space).\n",
    "* Option 2 -- Joint-space interpolation: computer for key waypoints, then interpolate joint values (faster but may not keep pencil exactly on straight line).\n",
    "* Interpolate smoothly by time using trapezoidal velocity profiles or cubic splines for position and quaternion slerp for orientations.\n",
    "\n",
    "**Pen Up / down :**\n",
    "* Implemnent `pen_up()` and `pen_down()` as :\n",
    "    * Move to hover height `+h` and then move in `x,y` to next start; or\n",
    "    * Use sservo to lift/lower pencil if tool supports it.\n",
    "* If using pen contact via Z offset, plan gentle lowering speed and small dwell time.\n",
    "\n",
    "**Pytho skeleton for path -> world -> IK -> execute**\n",
    "\n",
    "```\n",
    "def sample_path_2d(path2d, ds=0.001):\n",
    "    # path2d: list of segments, or list of (x,y) points\n",
    "    # return list of (x,y) sampled at spacing ds\n",
    "    # <-- implement based on your path source (SVG, parametric)\n",
    "    pass\n",
    "\n",
    "def plane_point_to_world(T, s, t):\n",
    "    # T from fit_plane_svd: columns u,v,n and origin as last column\n",
    "    u = T[0:3,0]; v = T[0:3,1]; origin = T[0:3,3]\n",
    "    return origin + s*u + t*v\n",
    "\n",
    "def pose_for_point(world_pos, normal, hover=False, hover_height=0.02, contact_depth=0.0):\n",
    "    # returns 4x4 pose with orientation: z axis = -normal (pencil points down)\n",
    "    z = -normal\n",
    "    # choose x axis along plane u (or derived)\n",
    "    # Here assume we have u available; else compute arbitrary orthonormal frame\n",
    "    # Build rotation R = [x y z]\n",
    "    # set position = world_pos + z * (hover_height if hover else contact_depth)\n",
    "    pass\n",
    "\n",
    "# For each pose:\n",
    "# 1) IK -> joints\n",
    "# 2) Interpolate between joints and command robot at reasonable rate\n",
    "# 3) Wait for completion or monitor joint reached\n",
    "\n",
    "```\n"
   ],
   "id": "62261e089e4055df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Quick example: calibrate with 3 points and draw a circle (complete small script)\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "# --- assume you have functions to move robot, read EE position and solve IK for your robot ---\n",
    "# probe_points = array of shape (N,3) recorded by touching surface\n",
    "probe_points = np.array([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.6, 0.15, 0.2],\n",
    "    [0.55, 0.2, 0.2],\n",
    "])\n",
    "\n",
    "T, u, v, normal, origin = fit_plane_svd(probe_points)\n",
    "\n",
    "# create 2D circle path in meters, center (0,0) radius 0.05\n",
    "angles = np.linspace(0, 2*np.pi, 300)\n",
    "circle2d = [(0.05*np.cos(a), 0.05*np.sin(a)) for a in angles]\n",
    "\n",
    "# convert to world poses and execute\n",
    "hover_h = 0.02   # 2 cm above plane\n",
    "contact_z = 0.0  # exactly on plane, or small negative for slight pressure\n",
    "\n",
    "for i, (s,t) in enumerate(circle2d):\n",
    "    pos_w = origin + s*u + t*v\n",
    "    # pose: position slightly above plane for first move, then lower\n",
    "    if i == 0:\n",
    "        goal_pos = pos_w + (-normal)*hover_h\n",
    "        move_robot_to_pose(goal_pos, orientation_from_axes(u, v, normal))\n",
    "        move_robot_to_pose(pos_w + (-normal)*0.001, orientation_from_axes(u, v, normal))  # touch lightly\n",
    "    else:\n",
    "        goal_pos = pos_w + (-normal)*0.001\n",
    "        joints = ik_solve(goal_pos, orientation_from_axes(u, v, normal))\n",
    "        command_robot_joints(joints)   # with interpolation/smoothness\n",
    "# lift pen\n",
    "move_robot_to_pose(origin + (-normal)*hover_h, orientation_from_axes(u, v, normal))\n",
    "\n",
    "```"
   ],
   "id": "b72077d974338574"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "90dc485eb3e3de7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
